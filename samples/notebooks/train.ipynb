{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00b3aed",
   "metadata": {},
   "source": [
    "# Object Detection with MPA\n",
    "To test this sample, 'data' folder should be linked to the location of this file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548bf78",
   "metadata": {},
   "source": [
    "## Import everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717eca7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ote_sdk.configuration.helper import create as create_parameters_from_parameters_schema\n",
    "from ote_sdk.entities.inference_parameters import InferenceParameters\n",
    "from ote_sdk.entities.label_schema import LabelSchemaEntity\n",
    "from ote_sdk.entities.model import ModelEntity, ModelOptimizationType, ModelPrecision, ModelStatus\n",
    "from ote_sdk.entities.model_template import parse_model_template, TargetDevice\n",
    "from ote_sdk.entities.resultset import ResultSetEntity\n",
    "from ote_sdk.entities.subset import Subset\n",
    "from ote_sdk.entities.task_environment import TaskEnvironment\n",
    "from ote_sdk.usecases.tasks.interfaces.export_interface import ExportType\n",
    "\n",
    "from ote_cli.datasets import get_dataset_class\n",
    "from ote_cli.registry import Registry\n",
    "from ote_cli.utils.importing import get_impl_class\n",
    "\n",
    "from mpa import MPAConstants\n",
    "\n",
    "\n",
    "print(f'pkg root = {MPAConstants.PACKAGE_ROOT}')\n",
    "print(f'recipes = {MPAConstants.RECIPES_PATH}')\n",
    "print(f'cwd = {os.getcwd()}')\n",
    "\n",
    "assert os.path.exists('./data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad843f",
   "metadata": {},
   "source": [
    "## Register templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c86d79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "templates_dir = '../../models/templates'\n",
    "registry = Registry(templates_dir)\n",
    "# registry = registry.filter(task_type=sys.executable.split(os.sep)[-4])\n",
    "print(registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a64b5",
   "metadata": {},
   "source": [
    "## Load model template and its hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f08de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_template = registry.get('Advanced_Transfer_Learning_for_VFNet_object_detection')\n",
    "hyper_parameters = model_template.hyper_parameters.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fbfd14",
   "metadata": {},
   "source": [
    "## Get dataset instantiated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43d83e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Dataset = get_dataset_class(model_template.task_type)\n",
    "\n",
    "# dataset_paths = {\n",
    "#     # 'train_ann_file' : './data/coco/annotations/semi_supervised/instances_train2017.1@0.1.json',\n",
    "#     # 'train_data_root' : './data/coco/annotations/train2017/',\n",
    "#     # 'val_ann_file' : './data/coco/annotations/semi_supervised/instances_val2017.1@0.1.json',\n",
    "#     # 'val_data_root' : './data/coco/annotations/val2017/',\n",
    "#     'train_ann_file' : './external/training_extensions/data/airport/annotation_faces_train.json',\n",
    "#     'train_data_root' : './external/training_extensions/data/airport/',\n",
    "#     'val_ann_file' : './external/training_extensions/data/airport/annotation_faces_train.json',\n",
    "#     'val_data_root' : './external/training_extensions/data/airport/',\n",
    "# }\n",
    "\n",
    "# dataset = Dataset(**dataset_paths)\n",
    "# labels_schema = LabelSchemaEntity.from_labels(dataset.get_labels())\n",
    "dataset = Dataset(\n",
    "    train_subset={'ann_file': '../../../../data/airport/annotation_faces_train.json',\n",
    "                  'data_root':  '../../../../data/airport/'},\n",
    "    val_subset={'ann_file': '../../../../data/airport/annotation_faces_train.json',\n",
    "                'data_root': '../../../../data/airport'}\n",
    ")\n",
    "labels_schema = LabelSchemaEntity.from_labels(dataset.get_labels())\n",
    "\n",
    "# print(f'validation dataset = {dataset.get_subset(Subset.VALIDATION)}')\n",
    "# for i, ditem in enumerate(dataset.get_subset(Subset.VALIDATION), 1):\n",
    "#     print(f'dataset item {i} = {ditem.numpy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c260bb",
   "metadata": {},
   "source": [
    "## Have a look at existing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c340c7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyper_parameters = create_parameters_from_parameters_schema(hyper_parameters)\n",
    "\n",
    "for p in hyper_parameters.learning_parameters.parameters:\n",
    "    print(f'{p}: {getattr(hyper_parameters.learning_parameters, p)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c28d21",
   "metadata": {},
   "source": [
    "## Tweak parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters.learning_parameters.batch_size = 16\n",
    "hyper_parameters.learning_parameters.num_iters = 150\n",
    "\n",
    "for p in hyper_parameters.learning_parameters.parameters:\n",
    "    print(f'{p}: {getattr(hyper_parameters.learning_parameters, p)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af16f4a",
   "metadata": {},
   "source": [
    "## Create Task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94afc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Task = get_impl_class(model_template.entrypoints.base)\n",
    "\n",
    "environment = TaskEnvironment(\n",
    "    model=None,\n",
    "    hyper_parameters=hyper_parameters,\n",
    "    label_schema=labels_schema,\n",
    "    model_template=model_template)\n",
    "        \n",
    "task = Task(task_environment=environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02f5fe",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd9896ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-26 13:54:57,044 | INFO : Saving checkpoint at 2 epochs\n",
      "2022-01-26 13:54:57,046 | INFO : ----------------- UnbiasedTeacher.state_dict_hook() called\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 5/5, 21.4 task/s, elapsed: 0s, ETA:     0s2022-01-26 13:54:57,733 | INFO : Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      "Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.006\n",
      "Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.000\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      "Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.006\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.124\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.124\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.124\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.000\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      "Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.350\n",
      "2022-01-26 13:54:57,774 | INFO : \n",
      "+----------+-------+\n",
      "| category | AP    |\n",
      "+----------+-------+\n",
      "| person   | 0.002 |\n",
      "+----------+-------+\n",
      "2022-01-26 13:54:57,783 | INFO : src dst diff: 0.2048126459121704\n",
      "2022-01-26 13:54:57,783 | INFO : Exp name: /tmp/MPA-task-grphr6ux/stage00_DetectionTrainer-train\n",
      "2022-01-26 13:54:57,783 | INFO : Epoch(val) [2][5]\tbbox_mAP: 0.0020, bbox_mAP_50: 0.0060, bbox_mAP_75: 0.0000, bbox_mAP_s: 0.0000, bbox_mAP_m: 0.0000, bbox_mAP_l: 0.0060, bbox_mAP_copypaste: 0.002 0.006 0.000 0.000 0.000 0.006\n",
      "2022-01-26 13:54:58,787 | INFO : run task done.\n",
      "2022-01-26 13:54:58,789 | INFO : infer()\n",
      "2022-01-26 13:54:58,791 | INFO : Confidence threshold 0.35\n",
      "2022-01-26 13:54:58,792 | INFO : initializing....\n",
      "2022-01-26 13:54:58,793 | INFO : called _init_recipe()\n",
      "2022-01-26 13:54:58,795 | INFO : train type = SemiSupervised\n",
      "2022-01-26 13:54:58,826 | INFO : initialized recipe = /mnt/hdd1/workspace/openvino/training_extensions/external/mpa/recipes/stages/detection/unbiased_teacher.yaml\n",
      "2022-01-26 13:54:58,830 | WARNING : Duplicate key is detected among bases [{'model'}]\n",
      "2022-01-26 13:54:58,833 | INFO : initialized.\n",
      "2022-01-26 13:54:58,834 | INFO : running task... kwargs = {}\n",
      "2022-01-26 13:54:58,834 | INFO : progress callback = None, hook name = ProgressUpdateHook\n",
      "2022-01-26 13:54:58,834 | INFO : called build_recipe()\n",
      "2022-01-26 13:54:58,834 | INFO : seems to be passed stage yaml...\n",
      "2022-01-26 13:54:58,835 | INFO : build_stage()\n",
      "2022-01-26 13:54:58,835 | INFO : work dir = /tmp/MPA-task-grphr6ux/stage00_DetectionInferrer-train\n",
      "2022-01-26 13:54:58,836 | INFO : CUDA_VISIBLE_DEVICES = None\n",
      "2022-01-26 13:54:58,836 | INFO : configured logger at /tmp/MPA-task-grphr6ux/stage00_DetectionInferrer-train with named 20220126_135458.log\n",
      "2022-01-26 13:54:58,836 | INFO : configure!: training=False\n",
      "2022-01-26 13:54:58,837 | INFO : configure_data()\n",
      "2022-01-26 13:54:58,837 | INFO : update_config() {'MinIouRandomCrop': {'min_crop_size': 0.1}, 'Resize': {'img_scale': (384, 384), 'multiscale_mode': 'range'}, 'Normalize': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'MultiScaleFlipAug': {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}}\n",
      "2022-01-26 13:54:58,838 | INFO : configure_data: Resize is updated with {'img_scale': (384, 384), 'multiscale_mode': 'range'}\n",
      "2022-01-26 13:54:58,838 | INFO : configure_data: Normalize is updated with {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}\n",
      "2022-01-26 13:54:58,838 | INFO : update_config() {'MinIouRandomCrop': {'min_crop_size': 0.1}, 'Resize': {'img_scale': (384, 384), 'multiscale_mode': 'range'}, 'Normalize': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'MultiScaleFlipAug': {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}}\n",
      "2022-01-26 13:54:58,838 | INFO : configure_data: MultiScaleFlipAug is updated with {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}\n",
      "2022-01-26 13:54:58,839 | INFO : update_config() {'MinIouRandomCrop': {'min_crop_size': 0.1}, 'Resize': {'img_scale': (384, 384), 'multiscale_mode': 'range'}, 'Normalize': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'MultiScaleFlipAug': {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}}\n",
      "2022-01-26 13:54:58,839 | INFO : configure_data: MultiScaleFlipAug is updated with {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}\n",
      "2022-01-26 13:54:58,839 | INFO : update_config() {'MinIouRandomCrop': {'min_crop_size': 0.1}, 'Resize': {'img_scale': (384, 384), 'multiscale_mode': 'range'}, 'Normalize': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'MultiScaleFlipAug': {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}}\n",
      "2022-01-26 13:54:58,840 | INFO : configure_data: Resize is updated with {'img_scale': (384, 384), 'multiscale_mode': 'range'}\n",
      "2022-01-26 13:54:58,840 | INFO : configure_data: Normalize is updated with {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}\n",
      "2022-01-26 13:54:58,840 | INFO : task config!!!!: training=False\n",
      "2022-01-26 13:54:58,965 | INFO : infer!\n",
      "2022-01-26 13:54:58,966 | INFO : Inferring on input source: data.test\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Use load_from_local loader\n",
      "2022-01-26 13:54:59,409 | INFO : ----------------- UnbiasedTeacher.load_state_dict_pre_hook() called\n",
      "2022-01-26 13:54:59,409 | INFO : ----------------- CustomVFNet.load_state_dict_pre_hook() called w/ prefix: model_s.\n",
      "2022-01-26 13:54:59,410 | INFO : ['person'] -> ['person'] ([0])\n",
      "2022-01-26 13:54:59,435 | INFO : ----------------- CustomVFNet.load_state_dict_pre_hook() called w/ prefix: model_t.\n",
      "2022-01-26 13:54:59,436 | INFO : ['person'] -> ['person'] ([0])\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 5/5, 21.6 task/s, elapsed: 0s, ETA:     0s2022-01-26 13:55:00,739 | INFO : run task done.\n",
      "2022-01-26 13:55:00,825 | INFO : Adjusting the confidence threshold\n",
      "2022-01-26 13:55:00,826 | INFO : Setting confidence threshold to 0.1 based on results\n",
      "2022-01-26 13:55:00,827 | INFO : Final model performance: Performance(score: 0.0, dashboard: (3 metric groups))\n",
      "2022-01-26 13:55:00,827 | INFO : called save_model\n",
      "2022-01-26 13:55:01,180 | INFO : train done.\n"
     ]
    }
   ],
   "source": [
    "output_model = ModelEntity(\n",
    "    dataset,\n",
    "    environment.get_model_configuration(),\n",
    "    model_status=ModelStatus.NOT_READY)\n",
    "\n",
    "task.train(dataset, output_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235b6a8",
   "metadata": {},
   "source": [
    "## Evaluate quality metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb7ffb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-26 13:55:01,455 | INFO : infer()\n",
      "2022-01-26 13:55:01,458 | INFO : Confidence threshold 0.1\n",
      "2022-01-26 13:55:01,459 | INFO : initializing....\n",
      "2022-01-26 13:55:01,460 | INFO : called _init_recipe()\n",
      "2022-01-26 13:55:01,462 | INFO : train type = SemiSupervised\n",
      "2022-01-26 13:55:01,499 | INFO : initialized recipe = /mnt/hdd1/workspace/openvino/training_extensions/external/mpa/recipes/stages/detection/unbiased_teacher.yaml\n",
      "2022-01-26 13:55:01,503 | WARNING : Duplicate key is detected among bases [{'model'}]\n",
      "2022-01-26 13:55:01,507 | INFO : initialized.\n",
      "2022-01-26 13:55:01,507 | INFO : running task... kwargs = {}\n",
      "2022-01-26 13:55:01,507 | INFO : progress callback = None, hook name = ProgressUpdateHook\n",
      "2022-01-26 13:55:01,507 | INFO : called build_recipe()\n",
      "2022-01-26 13:55:01,508 | INFO : seems to be passed stage yaml...\n",
      "2022-01-26 13:55:01,508 | INFO : build_stage()\n",
      "2022-01-26 13:55:01,509 | INFO : work dir = /tmp/MPA-task-grphr6ux/stage00_DetectionInferrer-train\n",
      "2022-01-26 13:55:01,509 | INFO : CUDA_VISIBLE_DEVICES = None\n",
      "2022-01-26 13:55:01,509 | INFO : configured logger at /tmp/MPA-task-grphr6ux/stage00_DetectionInferrer-train with named 20220126_135501.log\n",
      "2022-01-26 13:55:01,510 | INFO : configure!: training=False\n",
      "2022-01-26 13:55:01,510 | INFO : configure_data()\n",
      "2022-01-26 13:55:01,511 | INFO : update_config() {'MinIouRandomCrop': {'min_crop_size': 0.1}, 'Resize': {'img_scale': (384, 384), 'multiscale_mode': 'range'}, 'Normalize': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'MultiScaleFlipAug': {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}}\n",
      "2022-01-26 13:55:01,511 | INFO : configure_data: Resize is updated with {'img_scale': (384, 384), 'multiscale_mode': 'range'}\n",
      "2022-01-26 13:55:01,511 | INFO : configure_data: Normalize is updated with {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}\n",
      "2022-01-26 13:55:01,511 | INFO : update_config() {'MinIouRandomCrop': {'min_crop_size': 0.1}, 'Resize': {'img_scale': (384, 384), 'multiscale_mode': 'range'}, 'Normalize': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'MultiScaleFlipAug': {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}}\n",
      "2022-01-26 13:55:01,512 | INFO : configure_data: MultiScaleFlipAug is updated with {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}\n",
      "2022-01-26 13:55:01,512 | INFO : update_config() {'MinIouRandomCrop': {'min_crop_size': 0.1}, 'Resize': {'img_scale': (384, 384), 'multiscale_mode': 'range'}, 'Normalize': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'MultiScaleFlipAug': {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}}\n",
      "2022-01-26 13:55:01,512 | INFO : configure_data: MultiScaleFlipAug is updated with {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}\n",
      "2022-01-26 13:55:01,512 | INFO : update_config() {'MinIouRandomCrop': {'min_crop_size': 0.1}, 'Resize': {'img_scale': (384, 384), 'multiscale_mode': 'range'}, 'Normalize': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'MultiScaleFlipAug': {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}}\n",
      "2022-01-26 13:55:01,512 | INFO : configure_data: Resize is updated with {'img_scale': (384, 384), 'multiscale_mode': 'range'}\n",
      "2022-01-26 13:55:01,513 | INFO : configure_data: Normalize is updated with {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}\n",
      "2022-01-26 13:55:01,513 | INFO : task config!!!!: training=False\n",
      "2022-01-26 13:55:01,599 | INFO : infer!\n",
      "2022-01-26 13:55:01,599 | INFO : Inferring on input source: data.test\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Use load_from_local loader\n",
      "2022-01-26 13:55:02,006 | INFO : ----------------- UnbiasedTeacher.load_state_dict_pre_hook() called\n",
      "2022-01-26 13:55:02,007 | INFO : ----------------- CustomVFNet.load_state_dict_pre_hook() called w/ prefix: model_s.\n",
      "2022-01-26 13:55:02,007 | INFO : ['person'] -> ['person'] ([0])\n",
      "2022-01-26 13:55:02,032 | INFO : ----------------- CustomVFNet.load_state_dict_pre_hook() called w/ prefix: model_t.\n",
      "2022-01-26 13:55:02,033 | INFO : ['person'] -> ['person'] ([0])\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 5/5, 20.6 task/s, elapsed: 0s, ETA:     0s2022-01-26 13:55:04,329 | INFO : run task done.\n",
      "2022-01-26 13:55:04,346 | INFO : called evaluate()\n",
      "2022-01-26 13:55:04,350 | INFO : F-measure after evaluation: 0.0\n",
      "2022-01-26 13:55:04,350 | INFO : Evaluation completed\n",
      "Performance(score: 0.0, dashboard: (1 metric groups))\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = dataset.get_subset(Subset.VALIDATION)\n",
    "predicted_validation_dataset = task.infer(\n",
    "    validation_dataset.with_empty_annotations(),\n",
    "    InferenceParameters(is_evaluation=True))\n",
    "\n",
    "resultset = ResultSetEntity(\n",
    "    model=output_model,\n",
    "    ground_truth_dataset=validation_dataset,\n",
    "    prediction_dataset=predicted_validation_dataset,\n",
    ")\n",
    "task.evaluate(resultset)\n",
    "print(resultset.performance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4784e973",
   "metadata": {},
   "source": [
    "## Export model to OpenVINO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04d5f811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-26 13:55:04,691 | INFO : Exporting the model\n",
      "2022-01-26 13:55:04,693 | INFO : initializing....\n",
      "2022-01-26 13:55:04,695 | INFO : called _init_recipe()\n",
      "2022-01-26 13:55:04,696 | INFO : train type = SemiSupervised\n",
      "2022-01-26 13:55:04,713 | INFO : initialized recipe = /mnt/hdd1/workspace/openvino/training_extensions/external/mpa/recipes/stages/detection/unbiased_teacher.yaml\n",
      "2022-01-26 13:55:04,718 | WARNING : Duplicate key is detected among bases [{'model'}]\n",
      "2022-01-26 13:55:04,721 | INFO : initialized.\n",
      "2022-01-26 13:55:04,721 | INFO : running task... kwargs = {}\n",
      "2022-01-26 13:55:04,721 | INFO : progress callback = None, hook name = ProgressUpdateHook\n",
      "2022-01-26 13:55:04,721 | INFO : called build_recipe()\n",
      "2022-01-26 13:55:04,722 | INFO : seems to be passed stage yaml...\n",
      "2022-01-26 13:55:04,722 | INFO : build_stage()\n",
      "2022-01-26 13:55:04,723 | INFO : work dir = /tmp/MPA-task-grphr6ux/stage00_DetectionExporter-train\n",
      "2022-01-26 13:55:04,723 | INFO : CUDA_VISIBLE_DEVICES = None\n",
      "2022-01-26 13:55:04,723 | INFO : configured logger at /tmp/MPA-task-grphr6ux/stage00_DetectionExporter-train with named 20220126_135504.log\n",
      "2022-01-26 13:55:04,724 | INFO : exporting the model\n",
      "2022-01-26 13:55:04,724 | INFO : configure!: training=False\n",
      "2022-01-26 13:55:04,725 | INFO : configure_data()\n",
      "2022-01-26 13:55:04,725 | INFO : update_config() {'MinIouRandomCrop': {'min_crop_size': 0.1}, 'Resize': {'img_scale': (384, 384), 'multiscale_mode': 'range'}, 'Normalize': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'MultiScaleFlipAug': {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}}\n",
      "2022-01-26 13:55:04,725 | INFO : configure_data: Resize is updated with {'img_scale': (384, 384), 'multiscale_mode': 'range'}\n",
      "2022-01-26 13:55:04,725 | INFO : configure_data: Normalize is updated with {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}\n",
      "2022-01-26 13:55:04,726 | INFO : update_config() {'MinIouRandomCrop': {'min_crop_size': 0.1}, 'Resize': {'img_scale': (384, 384), 'multiscale_mode': 'range'}, 'Normalize': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'MultiScaleFlipAug': {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}}\n",
      "2022-01-26 13:55:04,726 | INFO : configure_data: MultiScaleFlipAug is updated with {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}\n",
      "2022-01-26 13:55:04,726 | INFO : update_config() {'MinIouRandomCrop': {'min_crop_size': 0.1}, 'Resize': {'img_scale': (384, 384), 'multiscale_mode': 'range'}, 'Normalize': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'MultiScaleFlipAug': {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}}\n",
      "2022-01-26 13:55:04,726 | INFO : configure_data: MultiScaleFlipAug is updated with {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}\n",
      "2022-01-26 13:55:04,726 | INFO : update_config() {'MinIouRandomCrop': {'min_crop_size': 0.1}, 'Resize': {'img_scale': (384, 384), 'multiscale_mode': 'range'}, 'Normalize': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'MultiScaleFlipAug': {'img_scale': (384, 384), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': False}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}}\n",
      "2022-01-26 13:55:04,727 | INFO : configure_data: Resize is updated with {'img_scale': (384, 384), 'multiscale_mode': 'range'}\n",
      "2022-01-26 13:55:04,727 | INFO : configure_data: Normalize is updated with {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}\n",
      "2022-01-26 13:55:04,727 | INFO : task config!!!!: training=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-26 13:55:04,972 - mmdet - INFO - load model from: torchvision://resnet50\n",
      "2022-01-26 13:55:04,973 - mmdet - INFO - Use load_from_torchvision loader\n",
      "2022-01-26 13:55:05,059 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-26 13:55:05,160 | INFO : ----------------- UnbiasedTeacher.state_dict_hook() called\n",
      "2022-01-26 13:55:05,163 | INFO : ----------------- UnbiasedTeacher.state_dict_hook() called\n",
      "2022-01-26 13:55:05,439 | INFO : ----------------- UnbiasedTeacher.state_dict_hook() called\n",
      "2022-01-26 13:55:05,442 | INFO : ----------------- UnbiasedTeacher.state_dict_hook() called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yunchu/workspace/openvino/training_extensions/mpa_env/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:661: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\"This model contains a squeeze operation on dimension \" + str(squeeze_dim) + \". If the model is \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model has been saved to \"/tmp/MPA-task-grphr6ux/stage00_DetectionExporter-train/export/model.onnx\"\n",
      "mo --input_model=/tmp/MPA-task-grphr6ux/stage00_DetectionExporter-train/export/model.onnx --mean_values=[123.675, 116.28, 103.53] --scale_values=[58.395, 57.12, 57.375] --output_dir=/tmp/MPA-task-grphr6ux/stage00_DetectionExporter-train/export --output=labels,boxes --data_type=FP32 --input_shape=[1, 3, 384, 384] --reverse_input_channels\n",
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/tmp/MPA-task-grphr6ux/stage00_DetectionExporter-train/export/model.onnx\n",
      "\t- Path for generated IR: \t/tmp/MPA-task-grphr6ux/stage00_DetectionExporter-train/export\n",
      "\t- IR output name: \tmodel\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tlabels,boxes\n",
      "\t- Input shapes: \t[1, 3, 384, 384]\n",
      "\t- Mean values: \t[123.675, 116.28, 103.53]\n",
      "\t- Scale values: \t[58.395, 57.12, 57.375]\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tNone\n",
      "\t- Reverse input channels: \tTrue\n",
      "ONNX specific parameters:\n",
      "\t- Inference Engine found in: \t/mnt/hdd1/workspace/openvino/training_extensions/mpa_env/lib/python3.8/site-packages/openvino\n",
      "Inference Engine version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n",
      "Model Optimizer version: \t2021.4.2-3976-0943ed67223-refs/pull/539/head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd1/workspace/openvino/training_extensions/mpa_env/lib/python3.8/site-packages/mo/mo/utils/versions_checker.py:170: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  req_ver = LooseVersion(required_v)\n",
      "/mnt/hdd1/workspace/openvino/training_extensions/mpa_env/lib/python3.8/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "exported_model = ModelEntity(\n",
    "    dataset,\n",
    "    environment.get_model_configuration(),\n",
    "    model_status=ModelStatus.NOT_READY)\n",
    "task.export(ExportType.OPENVINO, exported_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327b120",
   "metadata": {},
   "source": [
    "## Evaluate the exported model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b01094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "environment.model = exported_model\n",
    "ov_task = get_impl_class(model_template.entrypoints.openvino)(environment)\n",
    "predicted_validation_dataset = ov_task.infer(\n",
    "    validation_dataset.with_empty_annotations(),\n",
    "    InferenceParameters(is_evaluation=True))\n",
    "resultset = ResultSetEntity(\n",
    "    model=output_model,\n",
    "    ground_truth_dataset=validation_dataset,\n",
    "    prediction_dataset=predicted_validation_dataset,\n",
    ")\n",
    "ov_task.evaluate(resultset)\n",
    "print(resultset.performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810af6c",
   "metadata": {},
   "source": [
    "## Draw bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bae4d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import PIL\n",
    "print(predicted_validation_dataset)\n",
    "for predictions, item in zip(predicted_validation_dataset, validation_dataset.with_empty_annotations()):\n",
    "    image = item.numpy.astype(np.uint8)\n",
    "    print(f'annotation scene = {predictions.annotation_scene}')\n",
    "    for box in predictions.annotation_scene.shapes:\n",
    "        x1 = int(box.x1 * image.shape[1])\n",
    "        x2 = int(box.x2 * image.shape[1])\n",
    "        y1 = int(box.y1 * image.shape[0])\n",
    "        y2 = int(box.y2 * image.shape[0])\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 3)  \n",
    "        print(f'bbox {x1,y1}-{x2,y2}')\n",
    "    # IPython.display.display(PIL.Image.fromarray(image))\n",
    "    display(PIL.Image.fromarray(image))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8947a7b8322a93fbc31ac5b83c93c00981c5ee25f343d0ae1e3409bc4c51e0a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
